
version: '3'
x-airflow-common:
  &airflow-common
  image: apache/airflow:2.5.0
  environment:
    - AIRFLOW__CORE__EXECUTOR=CeleryExecutor
    - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres:5432/airflow
    - AIRFLOW__CORE__FERNET_KEY=FB0o_zt4e3Ziq3LdUUO7F2Z95cvFFx16hU8jTeR1ASM=
    - AIRFLOW__CORE__LOAD_EXAMPLES=False
    - AIRFLOW__CORE__LOGGING_LEVEL=INFO
    - AIRFLOW__CELERY__BROKER_URL=redis://:@redis:6379/0

  volumes:
    - ./dags:/opt/airflow/dags
    - ./airflow-data/logs:/opt/airflow/logs
    - ./airflow-data/plugins:/opt/airflow/plugins
    - ./airflow-data/airflow.cfg:/opt/airlfow/airflow.cfg
  depends_on:
    - postgres

services:
  postgres:
    image: postgres:14
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=airflow
      - POSTGRES_PORT=5432
    ports:
      - "5432:5432"
    volumes:
      - ./postgres-data:/var/lib/postgresql/data
      - ./airflow-data/airflow.cfg:/opt/airlfow/airflow.cfg

  airflow-init:
    << : *airflow-common
    container_name: airflow_init
    entrypoint: /bin/bash
    command:
      - -c
      - airflow users list || ( airflow db init &&
        airflow users create
          --role Admin
          --username airflow
          --password airflow
          --email airflow@airflow.com
          --firstname airflow
          --lastname airflow )
    restart: on-failure

  airflow-webserver:
    << : *airflow-common
    command: airflow webserver
    ports:
      - 8080:8080
    container_name: airflow_webserver
    restart: always
    # command: airflow db init


  airflow-scheduler:
    << : *airflow-common
    command: airflow scheduler
    container_name: airflow_scheduler
    restart: always
  
  # airflow-worker:
  #   << : *airflow-common
  #   command: celery worker
  #   container_name: airflow_worker
  #   restart: always
  #   depends_on:
  #     - postgres
  #   volumes:
  #     - ./dags:/opt/airflow/dags
  #     - ./data:/home/airflow/data
  #     - ./airflow-data/logs:/opt/airflow/logs
  #     - ./airflow-data/airflow.cfg:/opt/airlfow/airflow.cfg


  flower:
    <<: *airflow-common
    command: celery flower
    ports:
      - 5555:5555
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:5555/"]
      interval: 10s
      timeout: 10s
      retries: 5
    restart: always
  
  redis:
    image: redis:latest
    ports:
      - 6379:6379
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 30s
      retries: 50
    restart: always

  libreoffice-worker:
    << : *airflow-common
    image: libreoffice_converter
    build:
      context: ./libreoffice
      dockerfile: ./Dockerfile
    command: airflow celery worker
    container_name: libreoffice
    restart: always
    depends_on:
      - postgres
    volumes:
      - ./dags:/root/airflow/dags/
      - ./data:/root/airflow/data/
      - ./airflow-data/logs:/root/airflow/logs/
      - ./airflow-data/airflow.cfg:/opt/airlfow/airflow.cfg

